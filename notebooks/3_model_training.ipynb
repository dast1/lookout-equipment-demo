{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - Demonstration on an anonymized expander dataset\n",
    "*Part 3: Model training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = '<YOUR_BUCKET_NAME_HERE>'\n",
    "PREFIX = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "Following the data preparation notebook, this repository should now be structured as follow:\n",
    "```\n",
    "/lookout-equipment-demo\n",
    "|\n",
    "+-- data/\n",
    "|   |\n",
    "|   +-- labelled-data/\n",
    "|   |   \\-- labels.csv\n",
    "|   |\n",
    "|   \\-- training-data/\n",
    "|       \\-- expander/\n",
    "|           |-- subsystem-01\n",
    "|           |   \\-- subsystem-01.csv\n",
    "|           |\n",
    "|           |-- subsystem-02\n",
    "|           |   \\-- subsystem-02.csv\n",
    "|           |\n",
    "|           |-- ...\n",
    "|           |\n",
    "|           \\-- subsystem-24\n",
    "|               \\-- subsystem-24.csv\n",
    "|\n",
    "+-- dataset/\n",
    "|   |-- labels.csv\n",
    "|   |-- tags_description.csv\n",
    "|   |-- tags_list.txt\n",
    "|   |-- timeranges.txt\n",
    "|   \\-- timeseries.zip\n",
    "|\n",
    "+-- notebooks/\n",
    "|   |-- 1_data_preparation.ipynb\n",
    "|   |-- 2_dataset_creation.ipynb\n",
    "|   |-- 3_model_training.ipynb              <<< This notebook <<<\n",
    "|   |-- 4_model_evaluation.ipynb\n",
    "|   \\-- 5_inference_scheduling.ipynb\n",
    "|\n",
    "+-- utils/\n",
    "    |-- lookout_equipment_utils.py\n",
    "    \\-- lookoutequipment.json\n",
    "```\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip -q install --upgrade pip\n",
    "pip -q install --upgrade awscli boto3 sagemaker\n",
    "aws configure add-model --service-model file://../utils/lookoutequipment.json --service-name lookoutequipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA       = os.path.join('..', 'data')\n",
    "LABEL_DATA = os.path.join(DATA, 'labelled-data')\n",
    "TRAIN_DATA = os.path.join(DATA, 'training-data', 'expander')\n",
    "\n",
    "ROLE_ARN = sagemaker.get_execution_role()\n",
    "REGION_NAME = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our previous analysis, we will use the following time ranges:\n",
    "\n",
    "* **Train set:** 1st January 2015 - 31st August 2015: Lookout for Equipment needs at least 180 days of training data. March is one of the anomaly period tagged in the label, so this should not change the modeling behaviour.\n",
    "* **Test set:** 1st September 2015 - 30th November 2015 *(this test set should include both normal and abnormal data to evaluate our model on)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading time ranges:\n",
    "timeranges_fname = os.path.join(DATA, 'timeranges.txt')\n",
    "with open(timeranges_fname, 'r') as f:\n",
    "    timeranges = f.readlines()\n",
    "    \n",
    "training_start   = pd.to_datetime(timeranges[0][:-1])\n",
    "training_end     = pd.to_datetime(timeranges[1][:-1])\n",
    "evaluation_start = pd.to_datetime(timeranges[2][:-1])\n",
    "evaluation_end   = pd.to_datetime(timeranges[3][:-1])\n",
    "\n",
    "print(f'Training period: from {training_start} to {training_end}')\n",
    "print(f'Evaluation period: from {evaluation_start} to {evaluation_end}')\n",
    "\n",
    "dataset_fname = os.path.join(DATA, 'dataset_name.txt')\n",
    "with open(dataset_fname, 'r') as f:\n",
    "    DATASET_NAME = f.readline()\n",
    "    \n",
    "print('Dataset used:', DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_client = lookout.get_client(region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lookout_equipment_model(\n",
    "    sampling_rate, \n",
    "    model_name, \n",
    "    training_start, \n",
    "    training_end, \n",
    "    evaluation_start, \n",
    "    evaluation_end, \n",
    "    unsupervised=False, \n",
    "    schema=None\n",
    "):\n",
    "    TARGET_SAMPLING_RATE = sampling_rate\n",
    "\n",
    "    TRAINING_DATA_START_TIME   = training_start.to_pydatetime()\n",
    "    TRAINING_DATA_END_TIME     = training_end.to_pydatetime()\n",
    "    EVALUATION_DATA_START_TIME = evaluation_start.to_pydatetime()\n",
    "    EVALUATION_DATA_END_TIME   = evaluation_end.to_pydatetime()\n",
    "\n",
    "    LABEL_DATA_SOURCE_BUCKET   = BUCKET\n",
    "    LABEL_DATA_SOURCE_PREFIX   = f'{PREFIX}/labelled-data/'\n",
    "    labels_input_config = dict()\n",
    "    labels_input_config['S3InputConfiguration'] = dict([\n",
    "        ('Bucket', LABEL_DATA_SOURCE_BUCKET),\n",
    "        ('Prefix', LABEL_DATA_SOURCE_PREFIX)\n",
    "    ])\n",
    "\n",
    "    MODEL_NAME = model_name\n",
    "    \n",
    "    client_token = uuid.uuid4().hex\n",
    "    create_model_request = {\n",
    "        'ModelName': MODEL_NAME,\n",
    "        'DatasetName': DATASET_NAME,\n",
    "        'ClientToken': client_token,\n",
    "        'DataPreProcessingConfiguration': {\n",
    "            'TargetSamplingRate': TARGET_SAMPLING_RATE\n",
    "        },\n",
    "        'TrainingDataStartTime': TRAINING_DATA_START_TIME,\n",
    "        'TrainingDataEndTime': TRAINING_DATA_END_TIME,\n",
    "        'EvaluationDataStartTime': EVALUATION_DATA_START_TIME,\n",
    "        'EvaluationDataEndTime': EVALUATION_DATA_END_TIME\n",
    "    }\n",
    "    \n",
    "    if unsupervised == False:\n",
    "        create_model_request.update({\n",
    "            'RoleArn': ROLE_ARN,\n",
    "            'LabelsInputConfiguration': labels_input_config\n",
    "        })\n",
    "        \n",
    "    if schema is not None:\n",
    "        DATA_SCHEMA_FOR_MODEL = lookout.create_data_schema(schema)\n",
    "        data_schema_for_model = {\n",
    "            'InlineDataSchema': DATA_SCHEMA_FOR_MODEL,\n",
    "        }\n",
    "        create_model_request['DatasetSchema'] = data_schema_for_model\n",
    "\n",
    "    lookout_client = lookout.get_client(region_name=REGION_NAME)\n",
    "    return lookout_client.create_model(**create_model_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'lookout-demo-model-v1'\n",
    "model_response = train_lookout_equipment_model(\n",
    "    sampling_rate='PT5M',\n",
    "    model_name=MODEL_NAME,\n",
    "    training_start=training_start, \n",
    "    training_end=training_end, \n",
    "    evaluation_start=evaluation_start, \n",
    "    evaluation_end=evaluation_end,\n",
    "    unsupervised=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training is now in progress as captured by the console:\n",
    "    \n",
    "![Training in progress](../assets/model-training-in-progress.png)\n",
    "\n",
    "Use the following cell to capture the model training progress. **This model should take an hour to be trained.** Key drivers for training time are:\n",
    "* Number of labels in the label dataset (if provided)\n",
    "* Number of datapoints. This number depends on the sampling rate, the number of time series and the time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_model_response = lookout_client.describe_model(ModelName=MODEL_NAME)\n",
    "\n",
    "status = describe_model_response['Status']\n",
    "while status == 'IN_PROGRESS':\n",
    "    time.sleep(60)\n",
    "    describe_model_response = lookout_client.describe_model(ModelName=MODEL_NAME)\n",
    "    status = describe_model_response['Status']\n",
    "    print(str(pd.to_datetime(datetime.now(pytz.timezone(\"Europe/Paris\"))))[:19], \"| Model training:\", status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is now training and we can visualize the results of the back testing on the evaluation window selected at the beginning on this notebook:\n",
    "\n",
    "![Training complete](../assets/model-training-complete.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "In this notebook, we use the dataset created in part 2 of this notebook series and trained a Lookout for Equipment model.\n",
    "\n",
    "From here you can either head:\n",
    "* To the next notebook where we will **extract the evaluation data** for this model and use it to perform further analysis on the model results.\n",
    "* Or to the **inference scheduling notebook** where we will start the model, feed it some new data and catch the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
